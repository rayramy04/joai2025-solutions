# 日本人工知能オリンピック（JOAI）2025 - 解法解説とか

第一回となる日本人工知能オリンピック（JOAI）2025に参加して、金賞を受賞することができました！

忘れないうちに、簡単にですが考えていたことや感想を書こうと思います！

> 大学の課題をすっぽかしてJOAIに参加していたせいで今ヤバいので、説明が雑です🙇

[JOAI公式ホームページ](https://ioai-japan.org/)

[GitHub リポジトリ](https://github.com/rayramy04/joai2025-solutions)


## JOAIに参加しようと思った理由
- Twitterで流れてきたツイートでJOAIの存在を知る
- 人工知能の知識はなかったが、Kaggle形式のコンペと聞いて興味を持った
  - タイタニックコンペだけやったことがあった
- オンライン参加OK＆オープン枠（高校生以上も出られるが、日本代表には選ばれない枠）があったため、参加を決意

## 参加前の実力
- マレーシアの大学の情報学部1年生
  - 専門的な知識はまだ全然ない
- 機械学習やPythonのプログラミングは[東大松尾研のGCI](https://gci2.t.u-tokyo.ac.jp/)を少し前に修了した程度
- 深層学習は初体験だったが、大会1週間で勉強を頑張って入賞できた（自分でもビックリ）

> 本当の初心者なので、平然と間違ったことを書いているかもしれません。あくまで参考程度にお願いします。

## コンペの内容
- マルチモーダル分類タスク
  - 表（センサ値）、画像（赤外線）、テキスト（画像のキャプション）から「ガスの種類」を分類
> 詳細はこちらの方の記事を参照（同じく金賞受賞者）：
> [https://zenn.dev/kanda9685/articles/a6e9dc0cc89493](https://zenn.dev/kanda9685/articles/a6e9dc0cc89493)


## 工夫したこと・解法の要点まとめ
- 基本データ
  - 使用モデル（言語）：`microsoft/deberta-base`
  - 使用モデル（画像）：`resnet50.a1h_in1k`
  - センサデータはMLPで処理
  - Public：0.98431
  - Private：0.98128
  - 結果：オープン枠5位／全体10位（金賞受賞）
- チュートリアルコードをベースに改良したモデルを使った
  - 内容を把握し、ところどころルールの範囲内でChatGPTを活用して修正
  - 画像＋キャプション＋パラメータを活用した3モーダルモデルを採用
- 使用モデルはFacebookとMicrosoftで迷った
  - 最終的に性能の良かったresnet50.a1h_in1kを選択
- 画像には軽めのオーグメンテーションを追加
- ハイパーパラメータは時間がなかったのもあって手動で調整
- それぞれのフォールドのモデルをアンサンブル（平均）して最終予測
- 全ての実行は1~2時間で終わるようにして、最終日で急激にスコアを上昇させて上位に食い込んだ（計画性なさすぎ）
- 過学習対策が成功のカギだったコンペ
  - かなりの人がPublicとPrivateで順位が大きく異なっていた
  - もしかしたらかなりデータの分布がPublicと異なっていたのかも

## 解法解説
### EDAと特徴量の分析
- 欠損値なし／クラス分布もほぼ均等
- 特徴量は非常に少ない
  - センサ値2種
  - 赤外線画像
  - 説明文（テキスト）
- 特徴量エンジニアリングよりモデル構築の工夫が重要と判断

### モデル構築の試行錯誤
- チュートリアル（画像ベース）でF値0.89〜0.90くらいだった記憶
  - かなり上位で競り合うコンペになりそうだなと予想
  - 特徴量の数も少ないため、画像だけでは上位は難しいと判断
    - 他の要素も組み合わせることに
  - ただし、AI初心者が短期間で一から何かをするのは難しそうなので、チュートリアルをベースに戦おうと決意
- モデルはとりあえず最初は`microsoft/deberta-base`を使ってみた
- まず、色々な特徴量エンジニアリングを試した
  - センサに関する測定値
    - それぞれ足し合わせたり反転させたりして新たな特徴慮を作成
    - が、上手くいかなかった
  - 次に、キャプションのテキストを使ってみようと思った
    - キャプションには温度などが含まれていたので、℃や°Fの記号を使って温度だけを抜き出して機械学習の特徴量に加えた
    - しかし、スコアが下がった
- そのため、特徴量エンジニアリングは諦めて、基本は値を全部そのまま使うことにした

### 最終モデルの枠組み決定
- 3モーダル構成：センサ値＋画像＋キャプション
- 使用モデル（言語）：Microsoftの`microsoft/deberta-base`ベース
  - 言語モデルは許可済みのMicrosoftかFacebookのモデル、どちらを使うか迷った
  - 結局Facebookでもそこまで大きく変わらない性能はあった
  - が、MicrosoftのほうがFacebookの改良版らしいとの情報
  - 加えて、実験してみて若干精度が良かったためそちらを採用
  - マルチモーダルモデルの`openai/clip-vit-base-patch32`も使用可能であったが、こちらを用いたらスコアが下がったため断念
- 使用モデル（画像）：`resnet50.a1h_in1k`
- センサデータはMLPで処理
- 数値：特にひねりもなく、基本は標準化だけ
- キャプション：トークナイズしてモデルに入力
- 画像：軽めのオーグメンテーション
  - 画像をランダムに切り取ったり、反転させたり、色調を変えたり
  - ただし、本当にちょっとだけにしたほうがスコアが良かった

### ハイパーパラメータの調整
- この時点で、既に大会終了の2日前とかだったのでガチ焦り
- ハイパラチューニングはoputunaやベイズ最適化などを使っても良かったのだが...
  - 以前苦戦した経験があった＋その上、時間がなかった
- そのため、手動で実験して調節する脳筋作戦を実行することに
  - ChatGPTに聞きながらおすすめの値をある程度決めてもらう→手動で一つずつ変えて何がいいかを探索
- Fold数=5、エポック数=20前後がいいらしい
  - とChatGPTに教わったのだが、実際それでやったら上手くいった
  - スコアが頭打ちになった場合は、早期学習停止させるようにした
  - それ以上やっても過学習になるのが怖いなと思った＋時間がなかったのでこれに決定
- 画像のオーグメンテーションを調節
  - 色々追加してみたが、5種類前後の処理を軽～くだけ加えるのが良さそうだった
  - それ以上追加したり加工を強くすると精度が下がった
- 学習率
  - 元々は1e-4でやっていた
  - が、これも3e-4や5e-4にしたほうが精度が上がった
  - 3e-4にして、学習率スケジューラーで自動調節を行うことに

### 最終サブミットと結果
- この最終モデル調整が終わったのがコンペ終了の7時間前とか
- そこから1.5~2時間程度学習をさせて、ダメ元で提出したらまさかの受賞
- 最終日に0.94→0.98とスコアが上昇
- この時点では受賞はできなさそうだったが、いざフタを開けてみると順位が30位ほど上がっていた
  - Private: 0.98128, Public: 0.98431
  - オープン枠5位、全体10位
  - 入賞は諦めていたので、自分でも正直ビックリ
- かなりの人が順位を大幅に下げていた印象
  - やはり汎用性の高いモデルを作れるかがカギだったのだと思う

## 大切にしたこと
初心者なので、自分で一からコーディングして戦うのは無理。

そのため、深層学習の詳しい仕組みは分からない代わりに、
1. 大会の趣旨をメタ認知すること
2. チュートリアルを元に、ルールの範囲内でChatGPTを活用すること

で経験不足を補って戦った。

まず、運営が用意したデータや、学習済みモデルが制限されている意図を考えた。コーディングというよりは、戦略の面で効果を発揮した。

- データの種類が少ないので、全部使わないと上位入賞は難しそうだと考えられる
- お金がない高校生もいる＋モデルが制限されている
  - GPUリソースなどに依存しないコンペなのだろうと思った
  - 学習時間でのゴリ押しよりもアイデア重視に切り替えた
- PublicとPrivateが50%ずつで評価＋チュートリアルのF値が既に9割近かった
  - 汎用性が高いモデルにしろよ～という運営からの裏メッセージ
  - 結果、汎用性を重視したモデルにしたら順位がPrivateで30番上がった
  - かなり上位は均衡したスコアになることを予想
  - が、特徴量が少ないため、みんな似たようなモデルになると予想
  - そのため、ハイパラチューニングの精度やオーグメンテーションを泥臭く行った

また、先述の通り、基本的にコードの改良はチュートリアルを元にして、ChatGPTを活用しながら行った。

1. まずは自分で中身を読んで理解してみる
2. 分からないところが出てくるたびに、ChatGPTに質問 or ググる
3. 結果、なんとなくやっていること自体は分かるようになったので、中身を自分でいじってみるフェーズに突入
4. 深層学習のことは分からないが、GCIで習ったデータサイエンスの基礎知識は使えそうだったので使ってみた
   1. 何か特徴量を自分で作ったらいいんじゃね？
   2. チュートリアルのモデルをそのまま重ねてアンサンブルさせたら精度上がるんじゃね？
   3. ハイパラを変えてみたら精度上がるんじゃね？ ...などなど
5. あとは手動で実験を繰り返すのみ

## 感想
- 楽しかった！深層学習に興味を持つきっかけになった
- 深層学習が初めてだったのでチュートリアルのコードを読むのも一苦労
  - ChatGPTなど、分からないところは適宜質問することで上位勢と張り合えた
  - 良い成功体験になって、自信が付いた
- ただ、やっぱりいつも通り計画性がないのは反省
  - 普通に大学の課題が忙しくてスケジュール調整ができなかった
  - Kaggle初心者なので、実行環境のエラーで中断とかもあって焦った
  - でももう数日早く始めていればもっと良いスコアが出せそうだった
  - やっぱり余裕を持つ計画性、大事！
- 最後は運
  - 自分でも受賞、しかも金賞が取れるとは思ってもいなかった
  - 実際に深層学習を触ったことがない人がここまで来られたのはやっぱり運かもしれない
  - と思うので、これからも精進しようと思います
---
以上です。雑に書いてしまいましたが、また来年もやりたいです！運営の方々、このような機会を設けてくださってありがとうございました！

最終更新: 2025.07