{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":96289,"databundleVersionId":11435459,"sourceType":"competition"},{"sourceId":367330,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":304442,"modelId":324917}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 3モーダルモデル","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"#警告表示を避ける（実行時に固まることがあるため）\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:46:35.674782Z","iopub.execute_input":"2025-05-02T14:46:35.675260Z","iopub.status.idle":"2025-05-02T14:46:35.682816Z","shell.execute_reply.started":"2025-05-02T14:46:35.675233Z","shell.execute_reply":"2025-05-02T14:46:35.682179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# デバイスの確認\nimport torch\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU only\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:46:35.683439Z","iopub.execute_input":"2025-05-02T14:46:35.683664Z","iopub.status.idle":"2025-05-02T14:46:37.352780Z","shell.execute_reply.started":"2025-05-02T14:46:35.683642Z","shell.execute_reply":"2025-05-02T14:46:37.352140Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## データの読み込み","metadata":{"execution":{"iopub.status.busy":"2025-04-14T15:33:13.705736Z","iopub.execute_input":"2025-04-14T15:33:13.706365Z","iopub.status.idle":"2025-04-14T15:33:13.712427Z","shell.execute_reply.started":"2025-04-14T15:33:13.706335Z","shell.execute_reply":"2025-04-14T15:33:13.711095Z"}}},{"cell_type":"code","source":"# ライブラリのimport\nimport pandas as pd\nfrom pathlib import Path\n\n# データが格納されている場所を指定\nCOMPETITION_DATA_DIR = Path(\"/kaggle/input/joai-competition-2025\")\n\n# CSVファイルを読み込み、データフレームとして格納\ntrain_df = pd.read_csv(COMPETITION_DATA_DIR / 'train.csv')\ntest_df = pd.read_csv(COMPETITION_DATA_DIR / 'test.csv')\nsample_submission_df = pd.read_csv(COMPETITION_DATA_DIR / 'sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:46:37.353502Z","iopub.execute_input":"2025-05-02T14:46:37.353840Z","iopub.status.idle":"2025-05-02T14:46:37.753475Z","shell.execute_reply.started":"2025-05-02T14:46:37.353819Z","shell.execute_reply":"2025-05-02T14:46:37.752848Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## モデルの学習","metadata":{}},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport timm\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score, classification_report, f1_score, log_loss\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n\n\nfrom transformers import AutoTokenizer, AutoModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:46:37.755085Z","iopub.execute_input":"2025-05-02T14:46:37.755310Z","iopub.status.idle":"2025-05-02T14:46:41.278611Z","shell.execute_reply.started":"2025-05-02T14:46:37.755293Z","shell.execute_reply":"2025-05-02T14:46:41.277804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ハイパーパラメータの設定\n\n# 分類したいクラスは全部で4種類（Mixture, NoGas, Perfume, Smoke）\nNUM_CLASSES = 4\n\n# データの中で予測したい列の名前（ターゲット列）\nTARGET_COL = \"Gas\"\n\n# カテゴリ名（文字列）を数値のラベルに変換する辞書\nNAME2LABEL = {\"Mixture\": 0, \"NoGas\": 1, \"Perfume\": 2, \"Smoke\": 3}\n\n# 数値ラベルからカテゴリ名を取り出すための辞書\nLABEL2NAME = dict(zip(NAME2LABEL.values(), NAME2LABEL.keys()))\n\n@dataclass\nclass EnvConfig:\n    data_dir: Path = Path(\"/kaggle/input/joai-competition-2025\")\n    image_dir: Path = data_dir / \"images\"\n    train_path: Path = data_dir / \"train.csv\"\n    test_path: Path = data_dir / \"test.csv\"\n    model_save_dir: Path = Path(\"/kaggle/working/output\")\n\n    def __init__(self):\n        self.model_save_dir.mkdir(parents=True, exist_ok=True)\n\n\n@dataclass\nclass ExpConfig:\n    seed: int = 42\n    # 要修正\n    num_folds: int = 5 # 最後は6だが5のほうが良さそう\n    # 要修正\n    batch_size: int = 32\n    # 要修正\n    num_epochs: int = 18 # 15, 20などと変えてみた\n    # 要修正\n    learning_rate: float = 3e-4 #これが一番良さそう\n    num_workers: int = 4\n    img_model_name: str = \"resnet50.a1h_in1k\"\n    img_pretrained: bool = True\n\n    # 後で変更可能\n    text_model_name: str = \"FacebookAI/roberta-base\" # microsoft/deberta-baseと使い分け\n\n@dataclass\nclass Config:\n    env = EnvConfig()\n    exp = ExpConfig()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:46:41.279494Z","iopub.execute_input":"2025-05-02T14:46:41.279884Z","iopub.status.idle":"2025-05-02T14:46:41.287467Z","shell.execute_reply.started":"2025-05-02T14:46:41.279863Z","shell.execute_reply":"2025-05-02T14:46:41.286887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configクラスのインスタンスを作成（env, exp両方の設定が読み込まれる）\ncfg = Config()\n\n# ExpConfigのseedを参照してみる\ncfg.exp.seed  # 42という値が取得できる","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:46:41.288225Z","iopub.execute_input":"2025-05-02T14:46:41.288493Z","iopub.status.idle":"2025-05-02T14:46:41.316271Z","shell.execute_reply.started":"2025-05-02T14:46:41.288469Z","shell.execute_reply":"2025-05-02T14:46:41.315685Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### モデルの定義","metadata":{}},{"cell_type":"code","source":"class GasModel(nn.Module):\n    def __init__(self, cfg: Config):\n        super().__init__()\n        self.cfg = cfg\n\n        # 画像モデル（最終層なし）\n        self.img_model = timm.create_model(\n            cfg.exp.img_model_name,\n            pretrained=cfg.exp.img_pretrained,\n            num_classes=0\n        )\n        img_feat_dim = self.img_model.num_features  # e.g., 2048\n\n        # センサ用MLP（2次元 → 64次元）\n        self.sensor_mlp = nn.Sequential(\n            nn.Linear(2, 64),\n            nn.ReLU(),\n            nn.Linear(64, 64)\n        )\n\n        # テキストモデル（DeBERTa）\n        from transformers import AutoModel\n        self.text_model = AutoModel.from_pretrained(cfg.exp.text_model_name)\n        text_feat_dim = self.text_model.config.hidden_size  # e.g., 768\n\n        # 結合後の全結合層（2048 + 64 + 768 → 256 → 4）\n        self.classifier = nn.Sequential(\n            nn.Linear(img_feat_dim + 64 + text_feat_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, NUM_CLASSES)\n        )\n\n    def forward(self, x_img, x_sensor, input_ids, attention_mask):\n        # 画像特徴量\n        img_feat = self.img_model(x_img)  # (B, 2048)\n\n        # センサ特徴量\n        sensor_feat = self.sensor_mlp(x_sensor)  # (B, 64)\n\n        # テキスト特徴（CLSトークン）\n        text_outputs = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n        text_feat = text_outputs.last_hidden_state[:, 0, :]  # (B, 768)\n\n        # 結合 → 分類\n        x = torch.cat([img_feat, sensor_feat, text_feat], dim=1)\n        out = self.classifier(x)\n        return out\n\n\n# Configの設定を用いてGasModelのインスタンスを作成\nmodel = GasModel(cfg)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:46:41.317083Z","iopub.execute_input":"2025-05-02T14:46:41.317355Z","iopub.status.idle":"2025-05-02T14:46:45.451336Z","shell.execute_reply.started":"2025-05-02T14:46:41.317337Z","shell.execute_reply":"2025-05-02T14:46:45.450780Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Dataset","metadata":{}},{"cell_type":"code","source":"# Datasetクラスの定義とデータオーグメンテーション\n\nfrom torchvision import transforms\n\nclass TrainGasDataset(Dataset):\n    def __init__(self, cfg: Config, df: pd.DataFrame, tokenizer):\n        self.cfg = cfg\n        self.df = df\n        self.tokenizer = tokenizer\n\n        # 画像用のtransform（データオーグメンテーションを追加）\n        self.transform = transforms.Compose([\n            # ランダムに画像を切り取る（大きさを224x224に変更）\n            transforms.RandomResizedCrop(size=224, scale=(0.95, 1.0)),  # 少し緩やかにしてみた\n            # ランダムに画像を反転\n            transforms.RandomHorizontalFlip(p=0.5),\n            # ランダムに画像を回転（角度を小さく）\n            # transforms.RandomRotation(degrees=8), # ここも緩やかに。提出時は多分入れてない。\n            # 色調をランダムに変更（明るさ、コントラスト、色、シャープネスなど）\n            transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.05), # 範囲を縮小\n            # 画像をテンソルに変換\n            transforms.ToTensor(),\n            # 汎用性能を増加\n            transforms.RandomErasing(p=0.1, scale=(0.01, 0.05)), #追加した方がよさそう\n            # 画像を正規化（平均値と標準偏差を設定）\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225]),\n        ])\n\n\n        # センサーデータ用の変換（手動標準化）\n        self.sensor_mean = [0.0, 0.0]  # 例: MQ8とMQ5の平均\n        self.sensor_std = [1.0, 1.0]   # 例: 標準偏差（必要に応じて調整）\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n\n        # 画像読み込みと変換\n        img_path = self.cfg.env.image_dir / row[\"image_path_uuid\"]\n        image = Image.open(img_path).convert(\"RGB\")\n        image = self.transform(image)\n\n        # センサデータ（MQ8, MQ5）の取得と手動標準化\n        sensor = torch.tensor([row[\"MQ8\"], row[\"MQ5\"]], dtype=torch.float32)\n        sensor = (sensor - torch.tensor(self.sensor_mean)) / torch.tensor(self.sensor_std)  # 標準化\n\n        # キャプション → トークナイズ（DeBERTaなどの入力形式に変換）\n        caption = row[\"Caption\"]\n        tokenized = self.tokenizer(\n            caption,\n            padding=\"max_length\",\n            truncation=True,\n            max_length=64,\n            return_tensors=\"pt\"\n        )\n        input_ids = tokenized[\"input_ids\"].squeeze(0)  # (seq_len,)\n        attention_mask = tokenized[\"attention_mask\"].squeeze(0)\n\n        # ラベルの取得\n        label = NAME2LABEL[row[TARGET_COL]]\n\n        return {\n            \"image\": image,\n            \"sensor\": sensor,\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n            \"label\": label\n        }\n\n\nfrom transformers import AutoTokenizer\n\n# DeBERTaのトークナイザーを作成\ntokenizer = AutoTokenizer.from_pretrained(cfg.exp.text_model_name)\n\n# tokenizer を渡して Dataset を作成\ntrain_dataset = TrainGasDataset(cfg, train_df, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:46:45.452018Z","iopub.execute_input":"2025-05-02T14:46:45.452545Z","iopub.status.idle":"2025-05-02T14:46:45.718261Z","shell.execute_reply.started":"2025-05-02T14:46:45.452523Z","shell.execute_reply":"2025-05-02T14:46:45.717685Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepare_folds(train_df: pd.DataFrame, cfg: Config) -> pd.DataFrame:\n    \"\"\"\n    StratifiedKFoldを使って、train_dfにfoldカラム（交差検証の番号）を追加する\n    \"\"\"\n    # データ数だけ用意した配列をfold番号で埋める\n    fold_array = np.zeros(len(train_df), dtype=np.int32)\n    \n    # StratifiedKFold: ラベルのバランスを保ちながら複数の分割を作る\n    skf = StratifiedKFold(\n        n_splits=cfg.exp.num_folds,\n        shuffle=True,\n        random_state=cfg.exp.seed\n    )\n    \n    # valid_idxに該当するデータにfold番号を割り当てる\n    for fold, (_, valid_idx) in enumerate(skf.split(train_df, train_df[TARGET_COL])):\n        fold_array[valid_idx] = fold\n    \n    # 元のDataFrameにfoldカラムを追加して返す\n    train_df['fold'] = fold_array\n    return train_df\n\n# train_dfにfold列を追加（交差検証で使う）\ntrain_df = prepare_folds(train_df, cfg)\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:46:45.718877Z","iopub.execute_input":"2025-05-02T14:46:45.719094Z","iopub.status.idle":"2025-05-02T14:46:45.737957Z","shell.execute_reply.started":"2025-05-02T14:46:45.719076Z","shell.execute_reply":"2025-05-02T14:46:45.737217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 中身の確認\nsample = train_dataset[0]\n\n# 画像とラベルを取り出す\nimage = sample[\"image\"]\nlabel = sample[\"label\"]\n\n# 確認\nprint(image.shape)  # 例: torch.Size([3, 224, 224])\nprint(label)        # 例: 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:46:45.738790Z","iopub.execute_input":"2025-05-02T14:46:45.739070Z","iopub.status.idle":"2025-05-02T14:46:45.767986Z","shell.execute_reply.started":"2025-05-02T14:46:45.739045Z","shell.execute_reply":"2025-05-02T14:46:45.767393Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 学習・検証","metadata":{}},{"cell_type":"code","source":"# 各foldごとにcfg.exp.num_epochs回全ての学習用データを学習\n\n# 早期終了の活用\nclass EarlyStopping:\n    def __init__(self, patience=3, verbose=False):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if self.best_score is None:\n            self.best_score = val_loss\n        elif val_loss < self.best_score:\n            self.best_score = val_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n                if self.verbose:\n                    print(\"Early stopping triggered\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:46:45.768670Z","iopub.execute_input":"2025-05-02T14:46:45.768868Z","iopub.status.idle":"2025-05-02T14:46:45.774272Z","shell.execute_reply.started":"2025-05-02T14:46:45.768853Z","shell.execute_reply":"2025-05-02T14:46:45.773637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data.dataloader import default_collate\nfrom transformers import AutoTokenizer\nfrom torch.optim.lr_scheduler import CosineAnnealingLR  # 追加: スケジューラのインポート\n\ndef train_one_epoch(model, train_loader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0\n    for batch in tqdm(train_loader, desc=\"Training\"):\n        images = batch[\"image\"].to(device)\n        sensors = batch[\"sensor\"].to(device)\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"label\"].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images, sensors, input_ids, attention_mask)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    return total_loss / len(train_loader)  # 損失をバッチ数で割る\n\ndef validate(model, valid_loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    total_correct = 0\n    total_samples = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in tqdm(valid_loader, desc=\"Validation\"):\n            images = batch[\"image\"].to(device)\n            sensors = batch[\"sensor\"].to(device)\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            outputs = model(images, sensors, input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n\n            total_loss += loss.item()\n            predicted = outputs.argmax(dim=1)\n            total_correct += predicted.eq(labels).sum().item()\n            total_samples += labels.size(0)\n\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    avg_loss = total_loss / len(valid_loader)\n    accuracy = total_correct / total_samples\n    f1 = f1_score(all_labels, all_preds, average='weighted')\n    return avg_loss, accuracy, f1\n\ndef train_fold(fold: int, train_df: pd.DataFrame, cfg: Config, device):\n    print(f\"\\n{'*' * 20}\\nFold {fold}\")\n\n    tokenizer = AutoTokenizer.from_pretrained(cfg.exp.text_model_name)\n\n    train_fold_df = train_df[train_df['fold'] != fold].reset_index(drop=True)\n    valid_fold_df = train_df[train_df['fold'] == fold].reset_index(drop=True)\n\n    train_dataset = TrainGasDataset(cfg, train_fold_df, tokenizer)\n    valid_dataset = TrainGasDataset(cfg, valid_fold_df, tokenizer)\n\n    train_loader = DataLoader(\n        train_dataset, batch_size=cfg.exp.batch_size, shuffle=True,\n        num_workers=cfg.exp.num_workers, pin_memory=True, collate_fn=default_collate\n    )\n    valid_loader = DataLoader(\n        valid_dataset, batch_size=cfg.exp.batch_size, shuffle=False,\n        num_workers=cfg.exp.num_workers, pin_memory=True, collate_fn=default_collate\n    )\n\n    model = GasModel(cfg).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=cfg.exp.learning_rate)\n\n    # 追加: CosineAnnealingLR スケジューラの定義\n    scheduler = CosineAnnealingLR(optimizer, T_max=cfg.exp.num_epochs)\n\n    # early stoppingのインスタンスを作成\n    early_stopping = EarlyStopping(patience=5, verbose=True)\n    \n    for epoch in range(cfg.exp.num_epochs):\n        print(f\"Epoch {epoch}\")\n        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n        valid_loss, valid_accuracy, valid_f1 = validate(model, valid_loader, criterion, device)\n    \n        print(f\"Train Loss: {train_loss:.4f} | Valid Loss: {valid_loss:.4f} | \"\n              f\"Valid Accuracy: {valid_accuracy:.4f} | Valid F1: {valid_f1:.4f}\")\n    \n        # 追加: スケジューラのステップ（学習率を更新）\n        scheduler.step()\n    \n        # Early stoppingのチェック\n        early_stopping(valid_loss)\n        if early_stopping.early_stop:\n            print(\"Early stopping triggered\")\n            break\n    \n    # 最終モデルを保存\n    model_save_path = cfg.env.model_save_dir / f\"fold{fold}_epoch{cfg.exp.num_epochs - 1}.pth\"\n    torch.save(model.state_dict(), model_save_path)\n    print(f\"Model for fold {fold} saved to {model_save_path}\")\n    \n    return model  # 保存したモデルを返す","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:46:45.775072Z","iopub.execute_input":"2025-05-02T14:46:45.775272Z","iopub.status.idle":"2025-05-02T14:46:45.797447Z","shell.execute_reply.started":"2025-05-02T14:46:45.775257Z","shell.execute_reply":"2025-05-02T14:46:45.796750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CPUとGPUのどちらを使うかを自動判定（CUDAが使える環境ならGPUを使う）\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# fold数を設定\nfolds = cfg.exp.num_folds\n\n# 各foldで学習を行い、モデルを保存\nfor fold in range(folds):\n    train_fold(fold, train_df, cfg, device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 推論・提出ファイル作成","metadata":{}},{"cell_type":"code","source":"class TestGasDataset(Dataset):\n    def __init__(self, cfg: Config, df: pd.DataFrame, tokenizer):\n        self.cfg = cfg\n        self.df = df\n        self.tokenizer = tokenizer\n        \n        # 画像変換（リサイズと正規化）\n        self.transform = transforms.Compose([\n            transforms.Resize(224),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n        ])\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n\n        # 画像の読み込みと前処理\n        img_path = self.cfg.env.image_dir / row[\"image_path_uuid\"]\n        image = Image.open(img_path).convert(\"RGB\")\n        image = self.transform(image)\n\n        # センサ値（MQ8, MQ5）をTensor化\n        sensor = torch.tensor([row[\"MQ8\"], row[\"MQ5\"]], dtype=torch.float32)\n\n        # テキスト（Caption）をトークナイズ\n        caption = row[\"Caption\"]\n        text_input = self.tokenizer(\n            caption,\n            truncation=True,\n            padding=\"max_length\",\n            max_length=64,\n            return_tensors=\"pt\"\n        )\n        input_ids = text_input[\"input_ids\"].squeeze(0)      # (seq_len)\n        attention_mask = text_input[\"attention_mask\"].squeeze(0)\n\n        return {\n            \"image\": image,\n            \"sensor\": sensor,\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask\n        }\n\n\n\ndef run_inference(cfg: Config, device):\n    print(\"\\nStarting Inference\")\n    test_df = pd.read_csv(cfg.env.test_path)\n\n    # トークナイザーの準備\n    tokenizer = AutoTokenizer.from_pretrained(cfg.exp.text_model_name)\n\n    # TestDatasetの準備（テキストも渡す）\n    test_dataset = TestGasDataset(cfg, test_df, tokenizer)\n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=cfg.exp.batch_size,\n        shuffle=False,\n        num_workers=cfg.exp.num_workers,\n        pin_memory=True\n    )\n\n    all_preds = []  # 各foldの予測を格納するリスト\n\n    # 各foldで学習したモデルを使用して推論\n    for fold in range(cfg.num_folds):\n        model = GasModel(cfg).to(device)\n        model_checkpoint = cfg.env.model_save_dir / f\"fold{fold}_epoch{cfg.exp.num_epochs - 1}.pth\"\n        model.load_state_dict(torch.load(model_checkpoint, map_location=device, weights_only=True))\n        model.eval()\n\n        fold_preds = []  # 各foldの予測を格納\n        with torch.no_grad():\n            for batch in tqdm(test_loader, desc=f\"Inference fold {fold}\"):\n                images = batch[\"image\"].to(device)\n                sensors = batch[\"sensor\"].to(device)\n                input_ids = batch[\"input_ids\"].to(device)\n                attention_mask = batch[\"attention_mask\"].to(device)\n\n                # モデルにデータを渡す\n                outputs = model(images, sensors, input_ids, attention_mask)\n\n                # ソフトマックスを適用して確率を計算\n                batch_probs = torch.softmax(outputs, dim=1)\n                fold_preds.extend(batch_probs.cpu().numpy())\n\n        all_preds.append(np.array(fold_preds))  # 各foldの予測を保存\n\n    # アンサンブル（平均化）\n    final_preds = np.mean(all_preds, axis=0)  # 各foldの予測の平均を取る（アンサンブル）\n\n    return final_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:47:42.070151Z","iopub.execute_input":"2025-05-02T14:47:42.070716Z","iopub.status.idle":"2025-05-02T14:47:42.080924Z","shell.execute_reply.started":"2025-05-02T14:47:42.070690Z","shell.execute_reply":"2025-05-02T14:47:42.080273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 推論関数を呼び出して、各テストデータに対するクラスごとの確率を取得\nprobs = run_inference(cfg, device)\nprobs  # 全サンプル × 4クラス分の確率が入った配列","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:47:48.003613Z","iopub.execute_input":"2025-05-02T14:47:48.004353Z","iopub.status.idle":"2025-05-02T14:47:53.063200Z","shell.execute_reply.started":"2025-05-02T14:47:48.004329Z","shell.execute_reply":"2025-05-02T14:47:53.062571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 最も確率が高いクラスの番号を抽出（axis=1で行方向に処理）\npredicted_labels = probs.argmax(axis=1)\npredicted_labels  # 各サンプルの予測ラベル番号","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:47:55.694508Z","iopub.execute_input":"2025-05-02T14:47:55.695205Z","iopub.status.idle":"2025-05-02T14:47:55.701515Z","shell.execute_reply.started":"2025-05-02T14:47:55.695166Z","shell.execute_reply":"2025-05-02T14:47:55.700828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# そのままでは提出できないので、対応する文字列に変換\nLABEL2NAME","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:47:58.463355Z","iopub.execute_input":"2025-05-02T14:47:58.464165Z","iopub.status.idle":"2025-05-02T14:47:58.469629Z","shell.execute_reply.started":"2025-05-02T14:47:58.464132Z","shell.execute_reply":"2025-05-02T14:47:58.468909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# sample_submission を copy して提出用データフレームを作成\nsubmission_df = sample_submission_df.copy()\n\n# 「Gas」列に予測したクラス名を入れる\nsubmission_df['Gas'] = predicted_labels\n\n# ラベル番号から文字列のクラス名に変換\nsubmission_df['Gas'] = submission_df['Gas'].map(LABEL2NAME)\n\n# 先頭の数行を確認\nsubmission_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:48:00.222710Z","iopub.execute_input":"2025-05-02T14:48:00.222985Z","iopub.status.idle":"2025-05-02T14:48:00.236808Z","shell.execute_reply.started":"2025-05-02T14:48:00.222963Z","shell.execute_reply":"2025-05-02T14:48:00.236148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# csvファイルとして出力\n#submission_df.to_csv('submission.csv', index=False)\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T14:49:00.109524Z","iopub.execute_input":"2025-05-02T14:49:00.109961Z","iopub.status.idle":"2025-05-02T14:49:00.115725Z","shell.execute_reply.started":"2025-05-02T14:49:00.109933Z","shell.execute_reply":"2025-05-02T14:49:00.115040Z"}},"outputs":[],"execution_count":null}]}