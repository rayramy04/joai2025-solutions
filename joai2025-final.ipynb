{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# 3モーダルモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:46:35.675260Z",
     "iopub.status.busy": "2025-05-02T14:46:35.674782Z",
     "iopub.status.idle": "2025-05-02T14:46:35.682816Z",
     "shell.execute_reply": "2025-05-02T14:46:35.682179Z",
     "shell.execute_reply.started": "2025-05-02T14:46:35.675233Z"
    }
   },
   "outputs": [],
   "source": [
    "#警告表示を避ける（実行時に固まることがあるため）\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:46:35.683664Z",
     "iopub.status.busy": "2025-05-02T14:46:35.683439Z",
     "iopub.status.idle": "2025-05-02T14:46:37.352780Z",
     "shell.execute_reply": "2025-05-02T14:46:37.352140Z",
     "shell.execute_reply.started": "2025-05-02T14:46:35.683642Z"
    }
   },
   "outputs": [],
   "source": [
    "# デバイスの確認\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:33:13.706365Z",
     "iopub.status.busy": "2025-04-14T15:33:13.705736Z",
     "iopub.status.idle": "2025-04-14T15:33:13.712427Z",
     "shell.execute_reply": "2025-04-14T15:33:13.711095Z",
     "shell.execute_reply.started": "2025-04-14T15:33:13.706335Z"
    }
   },
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:46:37.353840Z",
     "iopub.status.busy": "2025-05-02T14:46:37.353502Z",
     "iopub.status.idle": "2025-05-02T14:46:37.753475Z",
     "shell.execute_reply": "2025-05-02T14:46:37.752848Z",
     "shell.execute_reply.started": "2025-05-02T14:46:37.353819Z"
    }
   },
   "outputs": [],
   "source": [
    "# ライブラリのimport\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# データが格納されている場所を指定\n",
    "COMPETITION_DATA_DIR = Path(\"/kaggle/input/joai-competition-2025\")\n",
    "\n",
    "# CSVファイルを読み込み、データフレームとして格納\n",
    "train_df = pd.read_csv(COMPETITION_DATA_DIR / 'train.csv')\n",
    "test_df = pd.read_csv(COMPETITION_DATA_DIR / 'test.csv')\n",
    "sample_submission_df = pd.read_csv(COMPETITION_DATA_DIR / 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:46:37.755310Z",
     "iopub.status.busy": "2025-05-02T14:46:37.755085Z",
     "iopub.status.idle": "2025-05-02T14:46:41.278611Z",
     "shell.execute_reply": "2025-05-02T14:46:41.277804Z",
     "shell.execute_reply.started": "2025-05-02T14:46:37.755293Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:46:41.279884Z",
     "iopub.status.busy": "2025-05-02T14:46:41.279494Z",
     "iopub.status.idle": "2025-05-02T14:46:41.287467Z",
     "shell.execute_reply": "2025-05-02T14:46:41.286887Z",
     "shell.execute_reply.started": "2025-05-02T14:46:41.279863Z"
    }
   },
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "\n",
    "# 分類したいクラスは全部で4種類（Mixture, NoGas, Perfume, Smoke）\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# データの中で予測したい列の名前（ターゲット列）\n",
    "TARGET_COL = \"Gas\"\n",
    "\n",
    "# カテゴリ名（文字列）を数値のラベルに変換する辞書\n",
    "NAME2LABEL = {\"Mixture\": 0, \"NoGas\": 1, \"Perfume\": 2, \"Smoke\": 3}\n",
    "\n",
    "# 数値ラベルからカテゴリ名を取り出すための辞書\n",
    "LABEL2NAME = dict(zip(NAME2LABEL.values(), NAME2LABEL.keys()))\n",
    "\n",
    "@dataclass\n",
    "class EnvConfig:\n",
    "    data_dir: Path = Path(\"/kaggle/input/joai-competition-2025\")\n",
    "    image_dir: Path = data_dir / \"images\"\n",
    "    train_path: Path = data_dir / \"train.csv\"\n",
    "    test_path: Path = data_dir / \"test.csv\"\n",
    "    model_save_dir: Path = Path(\"/kaggle/working/output\")\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExpConfig:\n",
    "    seed: int = 42\n",
    "    # 要修正\n",
    "    num_folds: int = 5 # 最後は6だが5のほうが良さそう\n",
    "    # 要修正\n",
    "    batch_size: int = 32\n",
    "    # 要修正\n",
    "    num_epochs: int = 18 # 15, 20などと変えてみた\n",
    "    # 要修正\n",
    "    learning_rate: float = 3e-4 #これが一番良さそう\n",
    "    num_workers: int = 4\n",
    "    img_model_name: str = \"resnet50.a1h_in1k\"\n",
    "    img_pretrained: bool = True\n",
    "\n",
    "    # 後で変更可能\n",
    "    text_model_name: str = \"microsoft/deberta-base\" # FacebookAI/roberta-baseと使い分け\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    env = EnvConfig()\n",
    "    exp = ExpConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:46:41.288493Z",
     "iopub.status.busy": "2025-05-02T14:46:41.288225Z",
     "iopub.status.idle": "2025-05-02T14:46:41.316271Z",
     "shell.execute_reply": "2025-05-02T14:46:41.315685Z",
     "shell.execute_reply.started": "2025-05-02T14:46:41.288469Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configクラスのインスタンスを作成（env, exp両方の設定が読み込まれる）\n",
    "cfg = Config()\n",
    "\n",
    "# ExpConfigのseedを参照してみる\n",
    "cfg.exp.seed  # 42という値が取得できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:46:41.317355Z",
     "iopub.status.busy": "2025-05-02T14:46:41.317083Z",
     "iopub.status.idle": "2025-05-02T14:46:45.451336Z",
     "shell.execute_reply": "2025-05-02T14:46:45.450780Z",
     "shell.execute_reply.started": "2025-05-02T14:46:41.317337Z"
    }
   },
   "outputs": [],
   "source": [
    "class GasModel(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # 画像モデル（最終層なし）\n",
    "        self.img_model = timm.create_model(\n",
    "            cfg.exp.img_model_name,\n",
    "            pretrained=cfg.exp.img_pretrained,\n",
    "            num_classes=0\n",
    "        )\n",
    "        img_feat_dim = self.img_model.num_features  # e.g., 2048\n",
    "\n",
    "        # センサ用MLP（2次元 → 64次元）\n",
    "        self.sensor_mlp = nn.Sequential(\n",
    "            nn.Linear(2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64)\n",
    "        )\n",
    "\n",
    "        # テキストモデル（DeBERTa）\n",
    "        from transformers import AutoModel\n",
    "        self.text_model = AutoModel.from_pretrained(cfg.exp.text_model_name)\n",
    "        text_feat_dim = self.text_model.config.hidden_size  # e.g., 768\n",
    "\n",
    "        # 結合後の全結合層（2048 + 64 + 768 → 256 → 4）\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(img_feat_dim + 64 + text_feat_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, NUM_CLASSES)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_img, x_sensor, input_ids, attention_mask):\n",
    "        # 画像特徴量\n",
    "        img_feat = self.img_model(x_img)  # (B, 2048)\n",
    "\n",
    "        # センサ特徴量\n",
    "        sensor_feat = self.sensor_mlp(x_sensor)  # (B, 64)\n",
    "\n",
    "        # テキスト特徴（CLSトークン）\n",
    "        text_outputs = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_feat = text_outputs.last_hidden_state[:, 0, :]  # (B, 768)\n",
    "\n",
    "        # 結合 → 分類\n",
    "        x = torch.cat([img_feat, sensor_feat, text_feat], dim=1)\n",
    "        out = self.classifier(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Configの設定を用いてGasModelのインスタンスを作成\n",
    "model = GasModel(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:46:45.452545Z",
     "iopub.status.busy": "2025-05-02T14:46:45.452018Z",
     "iopub.status.idle": "2025-05-02T14:46:45.718261Z",
     "shell.execute_reply": "2025-05-02T14:46:45.717685Z",
     "shell.execute_reply.started": "2025-05-02T14:46:45.452523Z"
    }
   },
   "outputs": [],
   "source": [
    "# Datasetクラスの定義とデータオーグメンテーション\n",
    "from torchvision import transforms\n",
    "\n",
    "class TrainGasDataset(Dataset):\n",
    "    def __init__(self, cfg: Config, df: pd.DataFrame, tokenizer):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        # 画像用のtransform（データオーグメンテーションを追加）\n",
    "        self.transform = transforms.Compose([\n",
    "            # ランダムに画像を切り取る（大きさを224x224に変更）\n",
    "            transforms.RandomResizedCrop(size=224, scale=(0.95, 1.0)),  # 少し緩やかにしてみた\n",
    "            # ランダムに画像を反転\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            # ランダムに画像を回転（角度を小さく）\n",
    "            # transforms.RandomRotation(degrees=8), # ここも緩やかに。提出時は入れていないが、入れるのもアリ。\n",
    "            # 色調をランダムに変更（明るさ、コントラスト、色、シャープネスなど）\n",
    "            transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.05), # 範囲を縮小\n",
    "            # 画像をテンソルに変換\n",
    "            transforms.ToTensor(),\n",
    "            # 汎用性能を増加\n",
    "            transforms.RandomErasing(p=0.1, scale=(0.01, 0.05)), #追加した方がよさそう\n",
    "            # 画像を正規化（平均値と標準偏差を設定）\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "\n",
    "        # センサーデータ用の変換（手動標準化）\n",
    "        self.sensor_mean = [0.0, 0.0]  # 例: MQ8とMQ5の平均\n",
    "        self.sensor_std = [1.0, 1.0]   # 例: 標準偏差（必要に応じて調整）\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        # 画像読み込みと変換\n",
    "        img_path = self.cfg.env.image_dir / row[\"image_path_uuid\"]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "\n",
    "        # センサデータ（MQ8, MQ5）の取得と手動標準化\n",
    "        sensor = torch.tensor([row[\"MQ8\"], row[\"MQ5\"]], dtype=torch.float32)\n",
    "        sensor = (sensor - torch.tensor(self.sensor_mean)) / torch.tensor(self.sensor_std)  # 標準化\n",
    "\n",
    "        # キャプション → トークナイズ（DeBERTaなどの入力形式に変換）\n",
    "        caption = row[\"Caption\"]\n",
    "        tokenized = self.tokenizer(\n",
    "            caption,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=64,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = tokenized[\"input_ids\"].squeeze(0)  # (seq_len,)\n",
    "        attention_mask = tokenized[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        # ラベルの取得\n",
    "        label = NAME2LABEL[row[TARGET_COL]]\n",
    "\n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"sensor\": sensor,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"label\": label\n",
    "        }\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# DeBERTaのトークナイザーを作成\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.exp.text_model_name)\n",
    "\n",
    "# tokenizer を渡して Dataset を作成\n",
    "train_dataset = TrainGasDataset(cfg, train_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:46:45.719094Z",
     "iopub.status.busy": "2025-05-02T14:46:45.718877Z",
     "iopub.status.idle": "2025-05-02T14:46:45.737957Z",
     "shell.execute_reply": "2025-05-02T14:46:45.737217Z",
     "shell.execute_reply.started": "2025-05-02T14:46:45.719076Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_folds(train_df: pd.DataFrame, cfg: Config) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    StratifiedKFoldを使って、train_dfにfoldカラム（交差検証の番号）を追加する\n",
    "    \"\"\"\n",
    "    # データ数だけ用意した配列をfold番号で埋める\n",
    "    fold_array = np.zeros(len(train_df), dtype=np.int32)\n",
    "    \n",
    "    # StratifiedKFold: ラベルのバランスを保ちながら複数の分割を作る\n",
    "    skf = StratifiedKFold(\n",
    "        n_splits=cfg.exp.num_folds,\n",
    "        shuffle=True,\n",
    "        random_state=cfg.exp.seed\n",
    "    )\n",
    "    \n",
    "    # valid_idxに該当するデータにfold番号を割り当てる\n",
    "    for fold, (_, valid_idx) in enumerate(skf.split(train_df, train_df[TARGET_COL])):\n",
    "        fold_array[valid_idx] = fold\n",
    "    \n",
    "    # 元のDataFrameにfoldカラムを追加して返す\n",
    "    train_df['fold'] = fold_array\n",
    "    return train_df\n",
    "\n",
    "# train_dfにfold列を追加（交差検証で使う）\n",
    "train_df = prepare_folds(train_df, cfg)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:46:45.739070Z",
     "iopub.status.busy": "2025-05-02T14:46:45.738790Z",
     "iopub.status.idle": "2025-05-02T14:46:45.767986Z",
     "shell.execute_reply": "2025-05-02T14:46:45.767393Z",
     "shell.execute_reply.started": "2025-05-02T14:46:45.739045Z"
    }
   },
   "outputs": [],
   "source": [
    "# 中身の確認\n",
    "sample = train_dataset[0]\n",
    "\n",
    "# 画像とラベルを取り出す\n",
    "image = sample[\"image\"]\n",
    "label = sample[\"label\"]\n",
    "\n",
    "# 確認\n",
    "print(image.shape)  # 例: torch.Size([3, 224, 224])\n",
    "print(label)        # 例: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習・検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:46:45.768868Z",
     "iopub.status.busy": "2025-05-02T14:46:45.768670Z",
     "iopub.status.idle": "2025-05-02T14:46:45.774272Z",
     "shell.execute_reply": "2025-05-02T14:46:45.773637Z",
     "shell.execute_reply.started": "2025-05-02T14:46:45.768853Z"
    }
   },
   "outputs": [],
   "source": [
    "# 各foldごとにcfg.exp.num_epochs回全ての学習用データを学習\n",
    "\n",
    "# 早期終了の活用\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "        elif val_loss < self.best_score:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.verbose:\n",
    "                    print(\"Early stopping triggered\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:46:45.775272Z",
     "iopub.status.busy": "2025-05-02T14:46:45.775072Z",
     "iopub.status.idle": "2025-05-02T14:46:45.797447Z",
     "shell.execute_reply": "2025-05-02T14:46:45.796750Z",
     "shell.execute_reply.started": "2025-05-02T14:46:45.775257Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import default_collate\n",
    "from transformers import AutoTokenizer\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR  # 追加: スケジューラのインポート\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        sensors = batch[\"sensor\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, sensors, input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)  # 損失をバッチ数で割る\n",
    "\n",
    "def validate(model, valid_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader, desc=\"Validation\"):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            sensors = batch[\"sensor\"].to(device)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(images, sensors, input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            total_correct += predicted.eq(labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(valid_loader)\n",
    "    accuracy = total_correct / total_samples\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    return avg_loss, accuracy, f1\n",
    "\n",
    "def train_fold(fold: int, train_df: pd.DataFrame, cfg: Config, device):\n",
    "    print(f\"\\n{'*' * 20}\\nFold {fold}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg.exp.text_model_name)\n",
    "\n",
    "    train_fold_df = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_fold_df = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = TrainGasDataset(cfg, train_fold_df, tokenizer)\n",
    "    valid_dataset = TrainGasDataset(cfg, valid_fold_df, tokenizer)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=cfg.exp.batch_size, shuffle=True,\n",
    "        num_workers=cfg.exp.num_workers, pin_memory=True, collate_fn=default_collate\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, batch_size=cfg.exp.batch_size, shuffle=False,\n",
    "        num_workers=cfg.exp.num_workers, pin_memory=True, collate_fn=default_collate\n",
    "    )\n",
    "\n",
    "    model = GasModel(cfg).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=cfg.exp.learning_rate)\n",
    "\n",
    "    # 追加: CosineAnnealingLR スケジューラの定義\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=cfg.exp.num_epochs)\n",
    "\n",
    "    # early stoppingのインスタンスを作成\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "    \n",
    "    for epoch in range(cfg.exp.num_epochs):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        valid_loss, valid_accuracy, valid_f1 = validate(model, valid_loader, criterion, device)\n",
    "    \n",
    "        print(f\"Train Loss: {train_loss:.4f} | Valid Loss: {valid_loss:.4f} | \"\n",
    "              f\"Valid Accuracy: {valid_accuracy:.4f} | Valid F1: {valid_f1:.4f}\")\n",
    "    \n",
    "        # 追加: スケジューラのステップ（学習率を更新）\n",
    "        scheduler.step()\n",
    "    \n",
    "        # Early stoppingのチェック\n",
    "        early_stopping(valid_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "    # 最終モデルを保存\n",
    "    model_save_path = cfg.env.model_save_dir / f\"fold{fold}_epoch{cfg.exp.num_epochs - 1}.pth\"\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model for fold {fold} saved to {model_save_path}\")\n",
    "    \n",
    "    return model  # 保存したモデルを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPUとGPUのどちらを使うかを自動判定（CUDAが使える環境ならGPUを使う）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# fold数を設定\n",
    "folds = cfg.exp.num_folds\n",
    "\n",
    "# 各foldで学習を行い、モデルを保存\n",
    "for fold in range(folds):\n",
    "    train_fold(fold, train_df, cfg, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論・提出ファイル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:47:42.070716Z",
     "iopub.status.busy": "2025-05-02T14:47:42.070151Z",
     "iopub.status.idle": "2025-05-02T14:47:42.080924Z",
     "shell.execute_reply": "2025-05-02T14:47:42.080273Z",
     "shell.execute_reply.started": "2025-05-02T14:47:42.070690Z"
    }
   },
   "outputs": [],
   "source": [
    "class TestGasDataset(Dataset):\n",
    "    def __init__(self, cfg: Config, df: pd.DataFrame, tokenizer):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        # 画像変換（リサイズと正規化）\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        # 画像の読み込みと前処理\n",
    "        img_path = self.cfg.env.image_dir / row[\"image_path_uuid\"]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "\n",
    "        # センサ値（MQ8, MQ5）をTensor化\n",
    "        sensor = torch.tensor([row[\"MQ8\"], row[\"MQ5\"]], dtype=torch.float32)\n",
    "\n",
    "        # テキスト（Caption）をトークナイズ\n",
    "        caption = row[\"Caption\"]\n",
    "        text_input = self.tokenizer(\n",
    "            caption,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=64,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = text_input[\"input_ids\"].squeeze(0)      # (seq_len)\n",
    "        attention_mask = text_input[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"sensor\": sensor,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def run_inference(cfg: Config, device):\n",
    "    print(\"\\nStarting Inference\")\n",
    "    test_df = pd.read_csv(cfg.env.test_path)\n",
    "\n",
    "    # トークナイザーの準備\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg.exp.text_model_name)\n",
    "\n",
    "    # TestDatasetの準備（テキストも渡す）\n",
    "    test_dataset = TestGasDataset(cfg, test_df, tokenizer)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=cfg.exp.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.exp.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    all_preds = []  # 各foldの予測を格納するリスト\n",
    "\n",
    "    # 各foldで学習したモデルを使用して推論\n",
    "    for fold in range(cfg.num_folds):\n",
    "        model = GasModel(cfg).to(device)\n",
    "        model_checkpoint = cfg.env.model_save_dir / f\"fold{fold}_epoch{cfg.exp.num_epochs - 1}.pth\"\n",
    "        model.load_state_dict(torch.load(model_checkpoint, map_location=device, weights_only=True))\n",
    "        model.eval()\n",
    "\n",
    "        fold_preds = []  # 各foldの予測を格納\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=f\"Inference fold {fold}\"):\n",
    "                images = batch[\"image\"].to(device)\n",
    "                sensors = batch[\"sensor\"].to(device)\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "                # モデルにデータを渡す\n",
    "                outputs = model(images, sensors, input_ids, attention_mask)\n",
    "\n",
    "                # ソフトマックスを適用して確率を計算\n",
    "                batch_probs = torch.softmax(outputs, dim=1)\n",
    "                fold_preds.extend(batch_probs.cpu().numpy())\n",
    "\n",
    "        all_preds.append(np.array(fold_preds))  # 各foldの予測を保存\n",
    "\n",
    "    # アンサンブル（平均化）\n",
    "    final_preds = np.mean(all_preds, axis=0)  # 各foldの予測の平均を取る（アンサンブル）\n",
    "\n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:47:48.004353Z",
     "iopub.status.busy": "2025-05-02T14:47:48.003613Z",
     "iopub.status.idle": "2025-05-02T14:47:53.063200Z",
     "shell.execute_reply": "2025-05-02T14:47:53.062571Z",
     "shell.execute_reply.started": "2025-05-02T14:47:48.004329Z"
    }
   },
   "outputs": [],
   "source": [
    "# 推論関数を呼び出して、各テストデータに対するクラスごとの確率を取得\n",
    "probs = run_inference(cfg, device)\n",
    "probs  # 全サンプル × 4クラス分の確率が入った配列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:47:55.695205Z",
     "iopub.status.busy": "2025-05-02T14:47:55.694508Z",
     "iopub.status.idle": "2025-05-02T14:47:55.701515Z",
     "shell.execute_reply": "2025-05-02T14:47:55.700828Z",
     "shell.execute_reply.started": "2025-05-02T14:47:55.695166Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最も確率が高いクラスの番号を抽出（axis=1で行方向に処理）\n",
    "predicted_labels = probs.argmax(axis=1)\n",
    "predicted_labels  # 各サンプルの予測ラベル番号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:47:58.464165Z",
     "iopub.status.busy": "2025-05-02T14:47:58.463355Z",
     "iopub.status.idle": "2025-05-02T14:47:58.469629Z",
     "shell.execute_reply": "2025-05-02T14:47:58.468909Z",
     "shell.execute_reply.started": "2025-05-02T14:47:58.464132Z"
    }
   },
   "outputs": [],
   "source": [
    "# そのままでは提出できないので、対応する文字列に変換\n",
    "LABEL2NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:48:00.222985Z",
     "iopub.status.busy": "2025-05-02T14:48:00.222710Z",
     "iopub.status.idle": "2025-05-02T14:48:00.236808Z",
     "shell.execute_reply": "2025-05-02T14:48:00.236148Z",
     "shell.execute_reply.started": "2025-05-02T14:48:00.222963Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample_submission を copy して提出用データフレームを作成\n",
    "submission_df = sample_submission_df.copy()\n",
    "\n",
    "# 「Gas」列に予測したクラス名を入れる\n",
    "submission_df['Gas'] = predicted_labels\n",
    "\n",
    "# ラベル番号から文字列のクラス名に変換\n",
    "submission_df['Gas'] = submission_df['Gas'].map(LABEL2NAME)\n",
    "\n",
    "# 先頭の数行を確認\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T14:49:00.109961Z",
     "iopub.status.busy": "2025-05-02T14:49:00.109524Z",
     "iopub.status.idle": "2025-05-02T14:49:00.115725Z",
     "shell.execute_reply": "2025-05-02T14:49:00.115040Z",
     "shell.execute_reply.started": "2025-05-02T14:49:00.109933Z"
    }
   },
   "outputs": [],
   "source": [
    "# csvファイルとして出力\n",
    "#submission_df.to_csv('submission.csv', index=False)\n",
    "submission_df.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11435459,
     "sourceId": 96289,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 324917,
     "modelInstanceId": 304442,
     "sourceId": 367330,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
